# red-teaming-portfolio
Red teaming portfolio: LLM safety testing, prompt attack/defense, eval design, and rubric-based analysis. Artifacts include writeups, sanitized examples, and lessons learnedâ€”focused on real-world reliability and responsible disclosure.
